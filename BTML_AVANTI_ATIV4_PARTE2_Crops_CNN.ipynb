{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##‚ö°Importa√ß√£o das Bibliotecas\n",
        "\n",
        "O cl√°ssico \"setup do projeto\", onde a gente importa todos os pacotes que vai usar mais pra frente."
      ],
      "metadata": {
        "id": "MjH_GvMaSow5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0o-QEzPsRp8J"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import shutil\n",
        "from shutil import copyfile\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.offsetbox import (TextArea, DrawingArea, OffsetImage,\n",
        "                                  AnnotationBbox)\n",
        "import matplotlib.patches as mpatches"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##‚ö†Ô∏è Observa√ß√£o sobre o uso do dataset\n",
        "\n",
        "Existem duas formas de acessar o dataset:\n",
        "\n",
        "‚úÖ Via opendatasets: Ideal para Google Colab. Permite baixar diretamente do Kaggle com od.download(url) ‚Äî √© necess√°rio fornecer suas credenciais do Kaggle (usu√°rio + API key).\n",
        "\n",
        "üîí Via caminho local (ex: /kaggle/input/...): Funciona apenas dentro dos notebooks do Kaggle, pois os dados j√° est√£o inclu√≠dos no ambiente e n√£o precisam ser baixados manualmente.\n",
        "\n",
        "‚ûï Use opendatasets no Colab ou Jupyter local.\n",
        "‚ûñ Use caminho local apenas se estiver rodando o notebook dentro da plataforma Kaggle.\n",
        "\n",
        "Nesse exemplo, os autores usaram o caminho direto do Kaggle, mas quando N√ìS fizermos isso no colab, precisamos importar com o opendatasets‚úå"
      ],
      "metadata": {
        "id": "HXUg8rqIUCY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir  = '/kaggle/input/agricultural-crops-image-classification/Agricultural-crops/'\n",
        "os.chdir(base_dir)"
      ],
      "metadata": {
        "id": "rOySGT-jS-C7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üóÇÔ∏è Inspe√ß√£o Inicial das Classes do Dataset\n",
        "\n",
        "* Detecta todas as pastas no diret√≥rio base (cada uma representa uma classe).\n",
        "\n",
        "* Conta quantas imagens existem em cada classe.\n",
        "\n",
        "* Armazena os nomes das classes e a primeira imagem de cada uma pra uso posterior.\n",
        "\n",
        "* Organiza tudo num DataFrame do pandas, ordenando pela quantidade de imagens por classe.\n",
        "\n",
        "üí° Isso √© √∫til pra identificar se o dataset est√° balanceado ou se h√° classes com muito mais imagens que outras (desequil√≠brio de classes)."
      ],
      "metadata": {
        "id": "Iv9eDyoNUx0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to list every directory name (label name)\n",
        "directories_list = tf.io.gfile.listdir(base_dir)\n",
        "\n",
        "# get number of labels\n",
        "len_labels = len(directories_list)\n",
        "print(f\"Total Class Labels = {len_labels}\")\n",
        "\n",
        "vis_images = []; vis_labels =[]\n",
        "length_file_list = []; label_list = []\n",
        "\n",
        "for item in directories_list:\n",
        "\n",
        "    # get each label directory\n",
        "    item_dir = os.path.join(base_dir, item)\n",
        "    # get list of images of each label\n",
        "    item_files = os.listdir(item)\n",
        "    # number of images per label\n",
        "    len_per_label = len(os.listdir(item))\n",
        "\n",
        "    length_file_list.append(len_per_label)\n",
        "    label_list.append(item)\n",
        "\n",
        "    # get first image of each label (for visualisation purpose)\n",
        "    vis_images.append(os.path.join(item_dir, item_files[0]))\n",
        "    # get respective label name (for visualisation purpose)\n",
        "    vis_labels.append(item)\n",
        "\n",
        "df_temp = pd.DataFrame({'Labels':label_list, 'Number of Images':length_file_list}).\\\n",
        "sort_values(by='Number of Images', ascending=False)\n",
        "df_temp"
      ],
      "metadata": {
        "id": "zjItxFW-W-yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " üñºÔ∏è Visualizando uma Imagem de Cada Classe\n",
        "\n",
        " Visualiza√ß√£o das primeiras imagens do dataset, uma pra cada classe.\n",
        "\n",
        " * Cria uma figura com subplots organizados em grade para exibir uma imagem de cada classe.\n",
        "\n",
        "* Usa as listas vis_images e vis_labels (criadas l√° atr√°s) pra carregar a primeira imagem representativa de cada categoria.\n",
        "\n",
        "* Remove ticks dos eixos, adiciona o r√≥tulo de cada imagem e um t√≠tulo geral.\n",
        "\n",
        "üëÄ Isso √© √≥timo pra ter uma visualiza√ß√£o r√°pida da variedade de classes e garantir que os dados est√£o organizados corretamente.\n",
        "\n",
        "üß† Tamb√©m ajuda a identificar poss√≠veis problemas como r√≥tulos trocados, imagens em branco, ou qualidade baixa de amostras."
      ],
      "metadata": {
        "id": "Wb0DcD2h-jXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(len(vis_labels)):\n",
        "    plt.subplot(6,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    img = mpimg.imread(vis_images[i])\n",
        "    plt.imshow(img)\n",
        "    plt.xlabel(vis_labels[i])\n",
        "    plt.suptitle(f\"Classifying {len_labels} Types of Image Labels\",fontsize=18, fontweight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uqDYsJHM-fM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rMySzVYf-e4Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîÄ Fun√ß√£o para Dividir os Dados em Treino e Valida√ß√£o\n",
        "\n",
        " √â um modo manual de dividir o dataset em treino e valida√ß√£o ‚Äî e com uma vantagem extra: ela ignora arquivos corrompidos (com tamanho 0 bytes)e ignora eles! üéØ\n",
        "\n",
        "* Usa random.sample pra sortear uma fra√ß√£o dos arquivos (SPLIT_SIZE) pro treino.\n",
        "\n",
        "* Coloca o restante no conjunto de valida√ß√£o.\n",
        "\n",
        "* Copia os arquivos para os diret√≥rios respectivos: TRAINING_DIR e VALIDATION_DIR.\n",
        "\n",
        "üîí A semente aleat√≥ria (random.seed(42)) garante que a divis√£o seja reprodut√≠vel ‚Äî ou seja, sempre vai gerar o mesmo resultado.\n",
        "\n",
        "üí° Essa abordagem funciona bem quando o dataset j√° est√° separado por pastas de classe, e voc√™ quer gerar divis√µes manuais sem usar ImageDataGenerator.flow_from_directory() ainda."
      ],
      "metadata": {
        "id": "NBaWj7cLnQke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n",
        "\n",
        "    selected_file_names = []\n",
        "    all_file_names = os.listdir(SOURCE_DIR)\n",
        "    for file_name in all_file_names:\n",
        "        file_path = os.path.join(SOURCE_DIR, file_name)\n",
        "        size = os.path.getsize(file_path)\n",
        "        if size != 0:\n",
        "              selected_file_names.append(file_name)\n",
        "        else:\n",
        "              print(f\"{file_name} is zero length, so ignoring.\")\n",
        "\n",
        "    random.seed(42)\n",
        "    selected_train_files = random.sample(selected_file_names, int(SPLIT_SIZE * len(selected_file_names)))\n",
        "    selected_val_files = [x for x in selected_file_names if x not in selected_train_files]\n",
        "\n",
        "    for file_name in selected_train_files:\n",
        "        source = os.path.join(SOURCE_DIR, file_name)\n",
        "        destination = os.path.join(TRAINING_DIR, file_name)\n",
        "        copyfile(source, destination)\n",
        "\n",
        "    for file_name in selected_val_files:\n",
        "        source = os.path.join(SOURCE_DIR, file_name)\n",
        "        destination = os.path.join(VALIDATION_DIR, file_name)\n",
        "        copyfile(source, destination)"
      ],
      "metadata": {
        "id": "oidF3dzznow2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üóÇÔ∏è Fun√ß√£o para Criar Pastas de Treino e Valida√ß√£o Organizadas por Classe\n",
        "\n",
        "Essa fun√ß√£o √© como o ‚Äúmodo autom√°tico‚Äù pra preparar as pastinhas de treino e valida√ß√£o pra cada classe. Ela organiza tudo bonitinho e ainda chama a fun√ß√£o split_data().\n",
        "\n",
        "* Percorre cada classe (cada pasta dentro do dataset).\n",
        "\n",
        "* Cria pastas espec√≠ficas pra treino e valida√ß√£o, organizadas assim:\n",
        "\n",
        "    * root_path/_MODELLING/training/<classe>/\n",
        "    * root_path/_MODELLING/validation/<classe>/\n",
        "\n",
        "* Chama a fun√ß√£o split_data() pra distribuir as imagens entre treino e valida√ß√£o, com o split_size definido (padr√£o = 90% treino, 10% valida√ß√£o).\n",
        "\n",
        "üßπ Antes de rodar essa fun√ß√£o, certifique-se de que os diret√≥rios _MODELLING/training e validation n√£o existem ainda, sen√£o o os.makedirs() pode lan√ßar erro.\n",
        "\n",
        "üí° Muito √∫til pra deixar os dados prontos pra ImageDataGenerator.flow_from_directory(), que espera justamente essa estrutura por pastas."
      ],
      "metadata": {
        "id": "FHkxLsSdsdd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_train_val_dirs(root_path, split_size = 0.9):\n",
        "    for item in directories_list:\n",
        "        source_dir = os.path.join(base_dir, item)\n",
        "        training_dir = os.path.join(root_path, f'_MODELLING/training/{item}')\n",
        "        validation_dir = os.path.join(root_path, f'_MODELLING/validation/{item}')\n",
        "\n",
        "        # Create EMPTY directory\n",
        "        os.makedirs(training_dir)\n",
        "        os.makedirs(validation_dir)\n",
        "\n",
        "        split_data(source_dir, training_dir, validation_dir, split_size)\n",
        "    print(f\"Created training and validation directories containing images at split size of {split_size}\")"
      ],
      "metadata": {
        "id": "JfTDZMWqtLoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöß Criando as Pastas com os Dados de Treino e Valida√ß√£o\n",
        "\n",
        "* Executa a fun√ß√£o create_train_val_dirs() que:\n",
        "\n",
        "* Cria as pastas para treino e valida√ß√£o.\n",
        "\n",
        "* Copia as imagens da pasta original (base_dir) para as novas pastas organizadas por classe.\n",
        "\n",
        "* Divide os dados com 90% para treino e 10% para valida√ß√£o (split_size = 0.9).\n",
        "\n",
        "üìÇ As imagens ficar√£o organizadas em\n",
        "* /kaggle/working/_MODELLING/training/ e\n",
        "* /kaggle/working/_MODELLING/validation/, prontos pra serem lidos por geradores de imagens.\n",
        "\n",
        "‚ö†Ô∏è Essa c√©lula pode demorar um pouco dependendo do tamanho do dataset, j√° que ela est√° copiando arquivos de forma individual."
      ],
      "metadata": {
        "id": "LXykB5TrtO-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "create_train_val_dirs('/kaggle/working', split_size = 0.9)"
      ],
      "metadata": {
        "id": "NEh9osQ9ty-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üñºÔ∏è Visualiza√ß√£o de Data Augmentation com ImageDataGenerator\n",
        "\n",
        "‚ú® Ela demonstra como o ImageDataGenerator transforma (aumenta) as imagens de forma autom√°tica, usando t√©cnicas de data augmentation.üé®\n",
        "\n",
        "* Carrega uma imagem de uma classe espec√≠fica.\n",
        "\n",
        "* Aplica quatro tipos diferentes de transforma√ß√£o usando o ImageDataGenerator:\n",
        "\n",
        "* Rota√ß√£o da imagem\n",
        "\n",
        "* Deslocamento horizontal\n",
        "\n",
        "* Zoom in/out\n",
        "\n",
        "* Espelhamento horizontal\n",
        "\n",
        "* Exibe 3 varia√ß√µes da imagem para cada tipo de transforma√ß√£o.\n",
        "\n",
        "üîÅ Isso ajuda o modelo a generalizar melhor, pois ele \"v√™\" diferentes vers√µes de uma mesma imagem durante o treino.\n",
        "\n",
        "üß™ Ideal pra verificar se o augmentation est√° funcionando como esperado antes de aplicar no pipeline de treinamento."
      ],
      "metadata": {
        "id": "cP4mdI7Wt3NE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_ImageDataGenerator(vis_images, vis_labels, image_index):\n",
        "    #Loads image in from the set image path\n",
        "    class_label = vis_labels[image_index]\n",
        "    img = tf.keras.preprocessing.image.load_img(vis_images[image_index], target_size= (250,250))\n",
        "    img_tensor = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "\n",
        "    #Creates our batch of one image\n",
        "    def show_image(datagen, param):\n",
        "        pic = datagen.flow(img_tensor, batch_size =1)\n",
        "        plt.figure(figsize=(10,3.5))\n",
        "        #Plots our figures\n",
        "        for i in range(1,4):\n",
        "            plt.subplot(1, 3, i)\n",
        "            batch = pic.next()\n",
        "            image_ = batch[0].astype('uint8')\n",
        "            plt.imshow(image_)\n",
        "        plt.suptitle(f\"Class: {class_label} \\n Image Generator ({param})\",fontsize=18, fontweight='bold')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    datagen = ImageDataGenerator(rotation_range=30)\n",
        "    show_image(datagen, \"rotation_range=30\")\n",
        "\n",
        "    datagen = ImageDataGenerator(width_shift_range=0.2)\n",
        "    show_image(datagen, \"width_shift_range=0.2\")\n",
        "\n",
        "    datagen = ImageDataGenerator(zoom_range=0.2)\n",
        "    show_image(datagen, \"zoom_range=0.2\")\n",
        "\n",
        "    datagen = ImageDataGenerator(horizontal_flip=True)\n",
        "    show_image(datagen, \"horizontal_flip=True\")\n",
        "\n",
        "show_ImageDataGenerator(vis_images, vis_labels, image_index = 0)"
      ],
      "metadata": {
        "id": "BB-KUCNsuyFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîÑ Aplicando Data Augmentation em Outra Imagem\n",
        "\n",
        "* Executa novamente a fun√ß√£o show_ImageDataGenerator, agora usando a quarta imagem (√≠ndice 3) da lista vis_images.\n",
        "\n",
        "* Exibe as transforma√ß√µes de data augmentation (rota√ß√£o, deslocamento, zoom e espelhamento) aplicadas a essa nova imagem.\n",
        "\n",
        "üéØ Isso serve pra explorar como o ImageDataGenerator afeta diferentes tipos de imagem no dataset ‚Äî uma √≥tima pr√°tica pra garantir que as transforma√ß√µes est√£o mantendo a coer√™ncia visual das classes."
      ],
      "metadata": {
        "id": "3INNICgwu0OP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_ImageDataGenerator(vis_images, vis_labels, image_index = 3)"
      ],
      "metadata": {
        "id": "Mn8T9MdRvR73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîÑ Fun√ß√£o para Criar os Geradores de Imagem (Treino e Valida√ß√£o)\n",
        "\n",
        "Aqui definimos uma fun√ß√£o super importante: criar os geradores de imagem para treino e valida√ß√£o, com data augmentation no treino e normaliza√ß√£o simples na valida√ß√£o.\n",
        "\n",
        "* Cria dois ImageDataGenerator:\n",
        "\n",
        "* Um com v√°rias transforma√ß√µes (rota√ß√£o, deslocamento, zoom, flip) para aumentar a variedade no conjunto de treino.\n",
        "\n",
        "* Outro apenas com rescale=1./255 para normalizar as imagens de valida√ß√£o.\n",
        "\n",
        "* Usa flow_from_directory() para gerar batches de imagens automaticamente a partir da estrutura de pastas:\n",
        "\n",
        "    *<TRAINING_DIR>/<classe1>/\n",
        "    *<TRAINING_DIR>/<classe2>/\n",
        "...\n",
        "* Retorna dois geradores que ser√£o usados no model.fit() mais adiante.\n",
        "\n",
        "‚ö†Ô∏è Aten√ß√£o: class_mode='binary' s√≥ funciona se houver duas classes. Se tiver mais, √© melhor usar class_mode='categorical'.\n",
        "\n",
        "üìê target_size=(150, 150) define o tamanho para o qual todas as imagens ser√£o redimensionadas."
      ],
      "metadata": {
        "id": "F_DH_JwOvWMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
        "\n",
        "    # Instantiate the ImageDataGenerator class (don't forget to set the arguments to augment the images)\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                     rotation_range=30,\n",
        "                                     width_shift_range=0.2,\n",
        "                                     height_shift_range=0.2,\n",
        "                                     shear_range=0.2,\n",
        "                                     zoom_range=0.2,\n",
        "                                     horizontal_flip=True,\n",
        "                                     fill_mode='nearest')\n",
        "\n",
        "    # Pass in the appropriate arguments to the flow_from_directory method\n",
        "    train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                      batch_size=32,\n",
        "                                                      class_mode='binary',\n",
        "                                                      target_size=(150, 150))\n",
        "\n",
        "    # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    # Pass in the appropriate arguments to the flow_from_directory method\n",
        "    validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
        "                                                                batch_size=32,\n",
        "                                                                class_mode='binary',\n",
        "                                                                target_size=(150, 150))\n",
        "    return train_generator, validation_generator"
      ],
      "metadata": {
        "id": "-lpY3fQ1we7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìÇ Definindo os Caminhos das Pastas de Treino e Valida√ß√£o\n",
        "\n",
        "* Usa os.path.join pra montar os caminhos completos das pastas de treino e valida√ß√£o dentro da pasta _MODELLING.\n",
        "\n",
        "* Imprime o caminho da pasta de valida√ß√£o para confer√™ncia.\n",
        "\n",
        "üîé Isso garante que as pr√≥ximas fun√ß√µes, como os geradores de imagem, saibam exatamente onde buscar os dados.\n",
        "\n",
        "‚úÖ Se estiver rodando no Colab, substitua '/kaggle/working' por '/content'."
      ],
      "metadata": {
        "id": "wy2bJLTJwjSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_dir = os.path.join('/kaggle/working', '_MODELLING', 'training')\n",
        "validation_dir = os.path.join('/kaggle/working', '_MODELLING', 'validation')\n",
        "\n",
        "print(validation_dir)"
      ],
      "metadata": {
        "id": "l1glJ6EbxLDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß™ Gerando os Batches de Imagens para Treino e Valida√ß√£o\n",
        "\n",
        "* Chama a fun√ß√£o train_val_generators() com os diret√≥rios de treino e valida√ß√£o definidos anteriormente.\n",
        "\n",
        "* Cria dois objetos:\n",
        "\n",
        "    * train_generator: que aplica data augmentation e fornece imagens em lotes para o treino.\n",
        "\n",
        "    * validation_generator: que fornece imagens normalizadas para valida√ß√£o, sem transforma√ß√£o.\n",
        "\n",
        "üì¶ Esses geradores s√£o ideais para uso com model.fit() porque entregam os dados em tempo real (sem precisar carregar tudo na mem√≥ria).\n",
        "\n",
        "üß† A partir daqui, j√° pode treinar modelos usando essas imagens em fluxo cont√≠nuo!"
      ],
      "metadata": {
        "id": "1TN2JCh6xMCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator, validation_generator = train_val_generators(training_dir, validation_dir)"
      ],
      "metadata": {
        "id": "bFwDzcSnxmXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† Definindo o Modelo 1 ‚Äì CNN Simples do Zero\n",
        "\n",
        "Define o primeiro modelo de rede neural convolucional (CNN) do projeto ‚Äî feito do zero, usando a API sequencial do Keras.\n",
        "\n",
        "Define uma CNN simples, com:\n",
        "\n",
        "* 2 camadas convolucionais + max pooling\n",
        "\n",
        "* Uma camada Flatten para transformar a imagem em vetor\n",
        "\n",
        "* Dropout de 50% para evitar overfitting\n",
        "\n",
        "* Uma camada densa de 1024 neur√¥nios\n",
        "\n",
        "* Camada de sa√≠da softmax, com n√∫mero de sa√≠das igual ao total de classes (len_labels)\n",
        "\n",
        "üìè A entrada √© uma imagem RGB de 150x150 pixels (input_shape=(150, 150, 3)).\n",
        "\n",
        "üßÆ A fun√ß√£o model_1.summary() exibe a arquitetura da rede com o total de par√¢metros trein√°veis.\n",
        "\n",
        "‚ö†Ô∏è Como √© uma softmax, esse modelo assume classifica√ß√£o multiclasse com classes mutuamente exclusivas."
      ],
      "metadata": {
        "id": "2MDzcWu_xobm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dense(len_labels, activation='softmax')\n",
        "])\n",
        "\n",
        "# Print the model summary\n",
        "model_1.summary()"
      ],
      "metadata": {
        "id": "PMeJA4lNyOEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚èπÔ∏è Callback para Parar o Treinamento com 80% de Acur√°cia\n",
        "\n",
        "Define um callback personalizado ‚Äî um tipo de ‚Äúvigia‚Äù que monitora o treino e interrompe automaticamente quando a acur√°cia chega a 80%. Super √∫til pra evitar overfitting e poupar tempo de computa√ß√£o.\n",
        "\n",
        "* Cria uma classe myCallback que herda de tf.keras.callbacks.Callback.\n",
        "\n",
        "* No final de cada √©poca (on_epoch_end), ela checa a acur√°cia (logs['accuracy']).\n",
        "\n",
        "* Se a acur√°cia passar de 80%, ela:\n",
        "\n",
        "* Imprime uma mensagem no console;\n",
        "\n",
        "* Interrompe o treinamento com self.model.stop_training = True.\n",
        "\n",
        "üß† Esse tipo de callback √© √∫til quando voc√™ quer evitar que o modelo ‚Äúcontinue treinando √† toa‚Äù depois de atingir um desempenho satisfat√≥rio.\n",
        "\n",
        "‚ö†Ô∏è Funciona apenas se a m√©trica accuracy estiver sendo monitorada no model.compile()."
      ],
      "metadata": {
        "id": "pvtYtMb6yQOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 80%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy')>0.8):\n",
        "            print(\"\\nReached 80% accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True\n",
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "rYdbL9AIy0-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚öôÔ∏è Compilando o Modelo 1 (CNN Simples)\n",
        "\n",
        "Aqui √© onde o modelo CNN √© compilado, ou seja, configurado com otimizador, fun√ß√£o de perda e m√©trica antes de ser treinado.\n",
        "\n",
        "* Otimizador: Usa o Adam, um dos otimizadores mais eficientes e populares para deep learning.\n",
        "\n",
        "* Taxa de aprendizado (learning_rate=0.001) define o ‚Äútamanho do passo‚Äù durante o ajuste dos pesos.\n",
        "\n",
        "* Fun√ß√£o de perda: sparse_categorical_crossentropy ‚Äî ideal quando os r√≥tulos das classes s√£o n√∫meros inteiros (ex: 0, 1, 2...) e n√£o one-hot encoded.\n",
        "\n",
        "* M√©trica: accuracy, para acompanhar a porcentagem de classifica√ß√µes corretas durante o treino e valida√ß√£o.\n",
        "\n",
        "üß† Lembrando: sparse_categorical_crossentropy espera que os r√≥tulos estejam em formato inteiro, diferente de categorical_crossentropy que exige one-hot (vetores bin√°rios)."
      ],
      "metadata": {
        "id": "PcZK2rhJy3Pf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "            loss = 'sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "GvWD_prb1zSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöÄ Treinando o Modelo 1\n",
        "\n",
        "Agora iniciamos o treinamento do modelo usando os dados gerados pelas pastas e com o callback de parada autom√°tica ativado.\n",
        "\n",
        "Treina o model_1 usando:\n",
        "\n",
        "* train_generator: imagens com data augmentation.\n",
        "\n",
        "* validation_generator: imagens normalizadas (sem transforma√ß√£o).\n",
        "\n",
        "* Executa por at√© 20 √©pocas, mas pode parar antes se a acur√°cia de treino passar de 80%, gra√ßas ao callbacks=callbacks.\n",
        "\n",
        "* Armazena o hist√≥rico do treinamento (loss, accuracy etc) no objeto history_1.\n",
        "\n",
        "üìà Esse hist√≥rico pode ser usado depois pra gerar gr√°ficos de desempenho com matplotlib.\n",
        "\n",
        "‚è±Ô∏è O tempo de execu√ß√£o depende do tamanho do dataset e do modelo. Com ImageDataGenerator, as imagens s√£o carregadas e transformadas em tempo real (√≥timo pra mem√≥ria!)."
      ],
      "metadata": {
        "id": "A0fFcBis13Fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_1 = model_1.fit(train_generator,\n",
        "                    epochs=20,\n",
        "                    validation_data=validation_generator,\n",
        "                    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "IRnzVjc1236g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Visualiza√ß√£o da Performance do Modelo (Acur√°cia & Perda)\n",
        "\n",
        "Nessa c√©lula, n√£o s√≥ plotamos os gr√°ficos de treino e valida√ß√£o, como ainda calculamos o gradiente (m) da curva, o que √© √≥timo pra entender se o modelo est√° melhorando de forma consistente.\n",
        "\n",
        "* Define uma fun√ß√£o vis_evaluation() para:\n",
        "\n",
        "* Plotar dois gr√°ficos lado a lado:\n",
        "\n",
        "* Acur√°cia de treino e valida√ß√£o\n",
        "\n",
        "* Perda (loss) de treino e valida√ß√£o\n",
        "\n",
        "* Calcular o gradiente da curva (m) ‚Äî a taxa de varia√ß√£o da m√©trica ao longo das √©pocas (tipo: \"o quanto melhorou por √©poca\").\n",
        "\n",
        "* Exibir essas informa√ß√µes visualmente com legendas e anota√ß√µes autom√°ticas nos gr√°ficos.\n",
        "\n",
        "Depois:\n",
        "\n",
        "* Extrai o hist√≥rico salvo durante o model.fit() com history_1.history\n",
        "\n",
        "* Chama a fun√ß√£o para visualizar os resultados do modelo 1 (CNN b√°sica)\n",
        "\n",
        "üìà Esse tipo de visualiza√ß√£o ajuda a identificar overfitting (ex: acur√°cia de treino sobe, mas a de valida√ß√£o n√£o) ou underfitting (quando ambas s√£o ruins).\n",
        "\n",
        "üß† O gradiente (\"m\") mostra se o modelo est√° melhorando de forma consistente ou se estagnou."
      ],
      "metadata": {
        "id": "MuwWQKMN28YJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vis_evaluation(history_dict, model_name):\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15, 6))\n",
        "    epochs = range(1, len(history_dict['accuracy'])+1)\n",
        "\n",
        "    def get_gradient(y_arr, epochs):\n",
        "        return round((y_arr[-1] - y_arr[0]) / (epochs[-1] - epochs[0]),2)\n",
        "\n",
        "    def vis_sub_evaluation(n, Accuracy, train_acc, val_acc, epochs):\n",
        "        axs[n].plot(epochs, train_acc, label=f'Training {Accuracy}', ls='--')\n",
        "        axs[n].plot(epochs, val_acc, label=f'Validation {Accuracy}', ls='dotted')\n",
        "\n",
        "        axs[n].set_title(f'Training and Validation {Accuracy}')\n",
        "        axs[n].set_xlabel('Epochs')\n",
        "        axs[n].set_ylabel(Accuracy)\n",
        "\n",
        "        handles, labels = axs[n].get_legend_handles_labels()\n",
        "        m_patch = mpatches.Patch(color='grey',label='m: gradient')\n",
        "        handles.append(m_patch)\n",
        "        axs[n].legend(handles=handles)\n",
        "\n",
        "        def annotate_box(train_acc):\n",
        "            return AnnotationBbox(TextArea(f\"m = {get_gradient(train_acc, epochs)}\"), (epochs[-1], train_acc[-1]),\n",
        "                            xybox=(20, 20),\n",
        "                            xycoords='data',\n",
        "                            boxcoords=\"offset points\",\n",
        "                            arrowprops=dict(arrowstyle=\"->\"))\n",
        "        axs[n].add_artist(annotate_box(train_acc))\n",
        "        axs[n].add_artist(annotate_box(val_acc))\n",
        "\n",
        "    train_acc = history_dict['accuracy']\n",
        "    val_acc = history_dict['val_accuracy']\n",
        "    vis_sub_evaluation(0, 'Accuracy', train_acc, val_acc, epochs)\n",
        "\n",
        "    train_loss = history_dict['loss']\n",
        "    val_loss = history_dict['val_loss']\n",
        "    vis_sub_evaluation(1, 'Loss', train_loss, val_loss, epochs)\n",
        "\n",
        "    plt.suptitle(f\"Performance Evaluation of {model_name}\",fontsize=18, fontweight='bold')\n",
        "    plt.show()\n",
        "\n",
        "history_dict_1 = history_1.history\n",
        "vis_evaluation(history_dict_1, 'Basic CNN')"
      ],
      "metadata": {
        "id": "J61Ss3m93vuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöÄ Carregando a Base do Modelo Pr√©-Treinado (VGG16)\n",
        "\n",
        "Entramos no territ√≥rio do Transfer Learning com VGG16 ‚Äî e essa c√©lula prepara o modelo pr√©-treinado para ser usado como base na nossa rede.\n",
        "\n",
        "* Carrega a arquitetura VGG16 pr√©-treinada no ImageNet, sem o topo (as camadas densas finais): include_top=False.\n",
        "\n",
        "* Define que nenhuma camada do modelo ser√° trein√°vel (layer.trainable = False), ou seja, a rede ser√° usada apenas como extratora de caracter√≠sticas visuais.\n",
        "\n",
        "* Conta e imprime o n√∫mero total de par√¢metros e quantos s√£o trein√°veis (neste caso, deve dar zero trein√°veis).\n",
        "\n",
        "üì¶ Transfer Learning = usar o \"conhecimento visual\" de um modelo j√° treinado em um grande dataset (como ImageNet) e aplicar em outro problema.\n",
        "\n",
        "üîí Congelar as camadas impede que os pesos da VGG sejam alterados ‚Äî √≥timo pra economizar tempo e evitar overfitting com datasets pequenos."
      ],
      "metadata": {
        "id": "SjgDKB3938I9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "pre_trained_model = VGG16(include_top=False,weights='imagenet', input_shape=(150, 150, 3))\n",
        "for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "total_params = pre_trained_model.count_params()\n",
        "num_trainable_params = sum([w.shape.num_elements() for w in pre_trained_model.trainable_weights])\n",
        "\n",
        "print(f\"There are {total_params:,} total parameters in this model.\")\n",
        "print(f\"There are {num_trainable_params:,} trainable parameters in this model.\")"
      ],
      "metadata": {
        "id": "V8dYHowv4YZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîç Explorando a Sa√≠da do Modelo Pr√©-Treinado\n",
        "\n",
        "Mostra como termina a VGG16 (a √∫ltima camada convolucional) e confirma o tipo do objeto que foi carregado.\n",
        "\n",
        "* Armazena a √∫ltima sa√≠da do modelo VGG16 congelado na vari√°vel last_output.\n",
        "\n",
        "* Essa sa√≠da √© o que ser√° usado como entrada para o \"topo personalizado\", que ser√° adicionado na pr√≥xima etapa.\n",
        "\n",
        "* Imprime o tipo do objeto carregado (tensorflow.keras.Model), confirmando que ele √© um modelo funcional do Keras.\n",
        "\n",
        "üìê A sa√≠da da VGG16 (sem o topo) √© um tensor 3D com v√°rias ativa√ß√µes (mapas de caracter√≠sticas) ‚Äî isso alimentar√° as camadas densas que v√™m a seguir.\n",
        "\n",
        "üîå Esse last_output ser√° conectado via Functional API ao novo \"topo\" que voc√™ vai construir."
      ],
      "metadata": {
        "id": "240DmXy34WmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "last_output = pre_trained_model.output\n",
        "print('last layer output: ', last_output)\n",
        "\n",
        "# Print the type of the pre-trained model\n",
        "print(f\"The pretrained model has type: {type(pre_trained_model)}\")"
      ],
      "metadata": {
        "id": "3SiThPFb6C7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß± Construindo o Modelo Final com Transfer Learning\n",
        "\n",
        "Fun√ß√£o que monta o modelo completo de Transfer Learning, usando a VGG16 congelada como base e adicionando um topo personalizado.\n",
        "\n",
        "* Achata (Flatten) a sa√≠da da VGG16 pra transformar os mapas de ativa√ß√£o num vetor 1D.\n",
        "\n",
        "* Adiciona:\n",
        "\n",
        "    * Uma camada densa com 1024 unidades e ReLU.\n",
        "\n",
        "    * Um dropout de 30% pra evitar overfitting.\n",
        "\n",
        "    * Uma camada final Dense com ativa√ß√£o softmax, com n√∫mero de sa√≠das igual ao total de classes (len_labels).\n",
        "\n",
        "* Cria um modelo final com a entrada original da VGG e a nova sa√≠da personalizada.\n",
        "\n",
        "‚öôÔ∏è A fun√ß√£o retorna o modelo completo, pronto pra compilar e treinar.\n",
        "\n",
        "üß† Isso √© o ‚Äúmelhor dos dois mundos‚Äù: aproveita o poder da VGG pra extrair padr√µes visuais e usa um classificador pr√≥prio pra sua tarefa."
      ],
      "metadata": {
        "id": "dK97KSoZ6SUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model\n",
        "\n",
        "def transfer_learning(last_output, pre_trained_model):\n",
        "    # Flatten da sa√≠da da VGG\n",
        "    x = tf.keras.layers.Flatten()(last_output)\n",
        "    # Camada densa com 1024 neur√¥nios e ativa√ß√£o ReLU\n",
        "    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "    # Dropout para reduzir overfitting\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    # Camada de sa√≠da com softmax para classifica√ß√£o multiclasse\n",
        "    x = tf.keras.layers.Dense(len_labels, activation='softmax')(x)\n",
        "\n",
        "    # Modelo final unindo entrada da VGG16 e novo topo\n",
        "    model = Model(inputs=pre_trained_model.input, outputs=x)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "sCuY6SKa7llH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß¨ Criando e Resumindo o Modelo com Transfer Learning (Modelo 2)\n",
        "\n",
        "O  modelo 2 est√° oficialmente criado! Essa c√©lula chama a fun√ß√£o que definimos e imprime o resumo da arquitetura completa ‚Äî VGG16 como base + seu topo customizado.\n",
        "\n",
        "Chama a fun√ß√£o transfer_learning() usando:\n",
        "\n",
        "* last_output: a sa√≠da da VGG16 (camadas convolucionais).\n",
        "\n",
        "* pre_trained_model: o modelo base congelado.\n",
        "\n",
        "Gera um modelo completo (model_2) com a entrada da VGG16 e uma nova \"cabe√ßa\" de classifica√ß√£o.\n",
        "\n",
        "Exibe um resumo com:\n",
        "\n",
        "* Quantidade de camadas\n",
        "\n",
        "* Formato das sa√≠das\n",
        "\n",
        "* Total de par√¢metros\n",
        "\n",
        "* Quantos s√£o trein√°veis (neste caso, s√≥ as camadas do topo)\n",
        "\n",
        "üìå As camadas da VGG16 est√£o congeladas (n√£o trein√°veis), ent√£o s√≥ o ‚Äútopo‚Äù √© atualizado durante o treinamento.\n",
        "\n",
        "üìà Ideal pra quando voc√™ quer boas representa√ß√µes visuais sem precisar treinar uma CNN do zero ‚Äî especialmente √∫til com datasets pequenos."
      ],
      "metadata": {
        "id": "Hqfjt9j_614c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = transfer_learning(last_output, pre_trained_model)\n",
        "model_2.summary()"
      ],
      "metadata": {
        "id": "9V4dJAI47vr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚öôÔ∏è Compilando o Modelo 2 (Transfer Learning com VGG16)\n",
        "\n",
        "Agora o modelo 2 (com VGG16) est√° sendo preparado pro combate! ‚öîÔ∏è\n",
        "Essa c√©lula faz a mesma etapa de compila√ß√£o que foi feita no modelo 1, s√≥ que agora aplicada ao modelo de Transfer Learning.\n",
        "\n",
        "* Usa o otimizador Adam, com taxa de aprendizado de 0.001.\n",
        "\n",
        "* Define a fun√ß√£o de perda como sparse_categorical_crossentropy, j√° que os r√≥tulos s√£o inteiros.\n",
        "\n",
        "* Monitora a acur√°cia como m√©trica principal.\n",
        "\n",
        "‚úÖ Mesmo padr√£o de compila√ß√£o usado no modelo 1 ‚Äî assim a compara√ß√£o entre eles ser√° justa.\n",
        "\n",
        "üß† Lembra que s√≥ as camadas do ‚Äútopo‚Äù do modelo s√£o trein√°veis aqui, ent√£o o treinamento deve ser mais r√°pido e menos propenso a overfitting."
      ],
      "metadata": {
        "id": "Kh7qYxFv7xXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "            loss = 'sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "i7MFyIqZ8N7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üöÄ Treinando o Modelo 2 (Transfer Learning com VGG16)\n",
        "\n",
        "üß†üî•Essa c√©lula d√° o start oficial no treinamento do modelo 2, agora usando a arquitetura VGG16 como base com o seu topo customizado. E ainda com o callback de parada autom√°tica ativado!\n",
        "\n",
        "* Inicia o treinamento do model_2, que usa a VGG16 como extratora de caracter√≠sticas e um topo denso customizado como classificador.\n",
        "\n",
        "* Treina por at√© 20 √©pocas, mas pode parar antes automaticamente se atingir 80% de acur√°cia (gra√ßas ao callbacks).\n",
        "\n",
        "* Usa os mesmos geradores train_generator e validation_generator definidos anteriormente.\n",
        "\n",
        "* Armazena o hist√≥rico do treinamento no objeto history_2.\n",
        "\n",
        "‚ö° Como s√≥ o topo do modelo √© trein√°vel, esse modelo costuma treinar mais r√°pido e atingir boa performance com menos √©pocas.\n",
        "\n",
        "üìä Esse hist√≥rico ser√° usado na pr√≥xima etapa para comparar os dois modelos visualmente."
      ],
      "metadata": {
        "id": "qbcg-NFU8PZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_2 = model_2.fit(train_generator,\n",
        "                    validation_data = validation_generator,\n",
        "                    epochs = 20,\n",
        "                    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "PJYYxzMa8rwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Visualiza√ß√£o da Performance do Modelo 2 (Transfer Learning)\n",
        "\n",
        "Fechamos com chave de ouro o ciclo de treinamento do modelo 2 ‚Äî ela visualiza o desempenho do modelo baseado em VGG16, do mesmo jeitinho que fez com o modelo 1 üåü\n",
        "\n",
        "* Extrai o hist√≥rico do treinamento (history_2.history) e armazena no dicion√°rio history_dict_2.\n",
        "\n",
        "* Chama a fun√ß√£o vis_evaluation() para gerar:\n",
        "\n",
        "* Gr√°fico de acur√°cia (treino x valida√ß√£o)\n",
        "\n",
        "* Gr√°fico de perda (loss) (treino x valida√ß√£o)\n",
        "\n",
        "* Com anota√ß√µes autom√°ticas mostrando o gradiente de melhoria (‚Äúm‚Äù).\n",
        "\n",
        "üìà Isso permite comparar visualmente a performance do modelo 2 com o modelo 1, e verificar qual teve melhor generaliza√ß√£o, menor perda e estabilidade nas curvas.\n",
        "\n",
        "üß† Uma curva de valida√ß√£o mais est√°vel e com menor perda geralmente indica menos overfitting ‚Äî ponto forte dos modelos com Transfer Learning."
      ],
      "metadata": {
        "id": "UX7IjqMR8tkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict_2 = history_2.history\n",
        "vis_evaluation(history_dict_2, 'Transfer Learning')"
      ],
      "metadata": {
        "id": "4ClP0hCy9NqD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}